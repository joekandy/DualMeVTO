{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c014d32e-d2a4-43fd-8ef3-79d1f0986267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detection_checkpoint.py:38   2025-02-26 17:56:58,855 [DetectionCheckpointer] Loading from ./ckpts/densepose/model_final_162be9.pkl ...\n",
      "checkpoint.py       :150  2025-02-26 17:56:58,857 [Checkpointer] Loading from ./ckpts/densepose/model_final_162be9.pkl ...\n",
      "detection_checkpoint.py:76   2025-02-26 17:56:59,055 Reading a file from 'Detectron2 Model Zoo'\n",
      "detection_checkpoint.py:38   2025-02-26 17:57:01,350 [DetectionCheckpointer] Loading from ./ckpts/densepose/model_final_162be9.pkl ...\n",
      "checkpoint.py       :150  2025-02-26 17:57:01,352 [Checkpointer] Loading from ./ckpts/densepose/model_final_162be9.pkl ...\n",
      "detection_checkpoint.py:76   2025-02-26 17:57:01,502 Reading a file from 'Detectron2 Model Zoo'\n",
      "model.py            :126  2025-02-26 17:57:25,035 Load pretrained model from ./ckpts/virtual_tryon.pth\n",
      "model.py            :126  2025-02-26 17:57:47,766 Load pretrained model from ./ckpts/virtual_tryon_dc.pth\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RunPod | ControlNet | Infer\n",
    "'''\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "from subprocess import call\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import runpod\n",
    "from runpod.serverless.utils import rp_download, rp_upload\n",
    "from runpod.serverless.utils.rp_validator import validate\n",
    "\n",
    "\n",
    "from prediction import leffa_predict\n",
    "import tempfile\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                    Schemas                                   #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "BASE_SCHEMA = {\n",
    "    'src_url': {'type': str, 'required': False, 'default': None},\n",
    "    'src_base64': {'type': str, 'required': False, 'default': None},\n",
    "    'ref_url': {'type': str, 'required': False, 'default': None},\n",
    "    'ref_base64': {'type': str, 'required': False, 'default': None},\n",
    "    # 'prompt': {'type': str, 'required': False, 'default': None},\n",
    "    # 'a_prompt': {'type': str, 'required': False, 'default': \"best quality, extremely detailed\"},\n",
    "    # 'n_prompt': {'type': str, 'required': False, 'default': \"longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality\"},\n",
    "    # 'num_samples': {'type': int, 'required': False, 'default': 1, 'constraints': lambda samples: samples in [1, 4]},\n",
    "    # 'image_resolution': {'type': int, 'required': False, 'default': 512, 'constraints': lambda resolution: resolution in [256, 512, 768]},\n",
    "    # 'ddim_steps': {'type': int, 'required': False, 'default': 20},\n",
    "    # 'scale': {'type': float, 'required': False, 'default': 9.0, 'constraints': lambda scale: 0.1 < scale < 30.0},\n",
    "    # 'seed': {'type': int, 'required': True},\n",
    "    # 'eta': {'type': float, 'required': False, 'default': 0.0},\n",
    "    # 'low_threshold': {'type': int, 'required': False, 'default': 100, 'constraints': lambda threshold: 1 < threshold < 255},\n",
    "    # 'high_threshold': {'type': int, 'required': False, 'default': 200, 'constraints': lambda threshold: 1 < threshold < 255},\n",
    "}\n",
    "\n",
    "def get_image(image_url, image_base64):\n",
    "    '''\n",
    "    Get the image from the provided URL or base64 string.\n",
    "    Returns a PIL image.\n",
    "    '''\n",
    "    if image_url is not None:\n",
    "        image = rp_download.file(image_url)\n",
    "        image = image['file_path']\n",
    "\n",
    "    if image_base64 is not None:\n",
    "        image_bytes = base64.b64decode(image_base64)\n",
    "        image = BytesIO(image_bytes)\n",
    "\n",
    "    input_image = Image.open(image)\n",
    "    input_image = np.array(input_image)\n",
    "\n",
    "    return input_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae4753d-8b8c-4ca6-a2d6-3e61b22ddc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = {'input':{\n",
    "        'src_url':'https://i.ebayimg.com/images/g/8UMAAOSwKiRe54FE/s-l1600.webp',\n",
    "        'ref_url':'https://www.wananluxury.com/cdn/shop/files/B2P00114CA893886_01_M_2025-02-26T10-41-48.706Z.jpg',\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b2af094-437e-4442-bd7d-b2cba159ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_folder = tempfile.mkdtemp()\n",
    "job_input = job['input']\n",
    "inputs = {}\n",
    "for img in ['src', 'ref']:\n",
    "    if job_input.get(F'{img}_url', None) is None and job_input.get(f'{img}_base64', None) is None:\n",
    "        print({'error': f'No {img} image provided. Please provide an {img}_url or {img}_base64.'})\n",
    "    elif job_input.get(f'{img}_url', None) is not None and job_input.get(f'{img}_base64', None) is not None:\n",
    "        print({'error': f'Both {img}_url and {img}_base64 provided. Please provide only one.'})\n",
    "    \n",
    "    # save image in temp folder\n",
    "    img_data = get_image(job_input.get(f'{img}_url', None), job_input.get(f'{img}_base64', None))\n",
    "    img_path = os.path.join(tmp_folder, f'{img}.png')\n",
    "    Image.fromarray(img_data).save(img_path)\n",
    "    inputs[img] = img_path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da06c7e-4600-469f-baad-99b169ff7b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/models/resnet.py:323: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/activations.py:116: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/downsampling.py:135: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/upsampling.py:145: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.21it/s]\n"
     ]
    }
   ],
   "source": [
    "result = leffa_predict(inputs['src'], inputs['ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2001979f-28e9-4200-ac52-e315ace5ece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/models/resnet.py:323: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/activations.py:116: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/downsampling.py:135: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/upsampling.py:145: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
      "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.25it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m output_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(result[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8))\n\u001b[1;32m      3\u001b[0m output_image\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m rp_upload\u001b[38;5;241m.\u001b[39mupload_image(\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "result = leffa_predict(inputs['src'], inputs['ref'])\n",
    "output_image = Image.fromarray(result[0].astype(np.uint8))\n",
    "output_image.save(os.path.join(tmp_folder, 'output.png'))\n",
    "output = rp_upload.upload_image(job['id'], os.path.join(tmp_folder, 'output.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544b127-8c99-4284-a47d-3e43aab13377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(job):\n",
    "    '''\n",
    "    Run a single prediction on the model.\n",
    "    '''\n",
    "    job_input = job['input']\n",
    "\n",
    "    tmp_folder = tempfile.mkdtemp()\n",
    "    inputs = {}\n",
    "    for img in ['src', 'ref']:\n",
    "        if job_input.get(F'{img}_url', None) is None and job_input.get(f'{img}_base64', None) is None:\n",
    "            return {'error': f'No {img} image provided. Please provide an {img}_url or {img}_base64.'}\n",
    "        elif job_input.get(f'{img}_url', None) is not None and job_input.get(f'{img}_base64', None) is not None:\n",
    "            return {'error': f'Both {img}_url and {img}_base64 provided. Please provide only one.'}\n",
    "        \n",
    "        # save image in temp folder\n",
    "        img_data = get_image(job_input.get(f'{img}_url', None), job_input.get(f'{img}_base64', None))\n",
    "        img_path = os.path.join(tmp_folder, f'{img}.png')\n",
    "        Image.fromarray(img_data).save(img_path)\n",
    "        inputs[img] = img_path\n",
    "        \n",
    "    result = leffa_predict(inputs['src'], inputs['ref'])\n",
    "    output_image = Image.fromarray(result[0].astype(np.uint8))\n",
    "    output_image.save(os.path.join(tmp_folder, 'output.png'))\n",
    "    output = rp_upload.upload_image(job['id'], os.path.join(tmp_folder, 'output.png'))\n",
    "    return output\n",
    "\n",
    "\n",
    "    # # --------------------------------- Openpose --------------------------------- #\n",
    "    # elif MODEL_TYPE == \"openpose\":\n",
    "    #     openpose_validate = validate(job_input, OPENPOSE_SCHEMA)\n",
    "    #     if 'errors' in openpose_validate:\n",
    "    #         return {'error': openpose_validate['errors']}\n",
    "    #     validated_input = openpose_validate['validated_input']\n",
    "\n",
    "    #     outputs = process_pose(\n",
    "    #         get_image(validated_input['image_url'], validated_input['image_base64']),\n",
    "    #         validated_input['prompt'],\n",
    "    #         validated_input['a_prompt'],\n",
    "    #         validated_input['n_prompt'],\n",
    "    #         validated_input['num_samples'],\n",
    "    #         validated_input['image_resolution'],\n",
    "    #         validated_input['detect_resolution'],\n",
    "    #         validated_input['ddim_steps'],\n",
    "    #         validated_input['scale'],\n",
    "    #         validated_input['seed'],\n",
    "    #         validated_input['eta'],\n",
    "    #         model,\n",
    "    #         ddim_sampler,\n",
    "    #     )\n",
    "\n",
    "    # # outputs from list to PIL\n",
    "    # outputs = [Image.fromarray(output) for output in outputs]\n",
    "\n",
    "    # # save outputs to file\n",
    "    # os.makedirs(\"tmp\", exist_ok=True)\n",
    "    # outputs = [output.save(f\"tmp/output_{i}.png\") for i, output in enumerate(outputs)]\n",
    "\n",
    "    # for index, output in enumerate(outputs):\n",
    "    #     outputs = rp_upload.upload_image(job['id'], f\"tmp/output_{index}.png\")\n",
    "\n",
    "    # # return paths to output files\n",
    "    # return outputs\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                     Main                                     #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "# parser = argparse.ArgumentParser(description=__doc__)\n",
    "# parser.add_argument(\"--model_type\", type=str,\n",
    "#                     default=None, help=\"Model URL\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    runpod.serverless.start({\"handler\": predict})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
